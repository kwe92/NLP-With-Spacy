{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationSummary:\n",
    "    \n",
    "    def __init__(self, y_true: np.array ,y_pred: np.array):\n",
    "        \n",
    "        self.__y_true: array = y_true\n",
    "        self.__y_pred: array = y_pred\n",
    "        self.__confusion_matrix: np.ndarray\n",
    "        self.__sensitivity: float\n",
    "        self.__specificity: float\n",
    "        self.__accuracy: float\n",
    "        self.missclassification_error: float\n",
    "        self.__recall_score: float\n",
    "        self.__precision_score: float\n",
    "        self.__summary_data()\n",
    "    \n",
    "    @property\n",
    "    def y_true(self):\n",
    "        return self.__y_true\n",
    "    \n",
    "    @property\n",
    "    def y_pred(self):\n",
    "        return self.__y_pred\n",
    "    \n",
    "    @property\n",
    "    def confusion_matrix(self):\n",
    "        return self.__confusion_matrix\n",
    "    \n",
    "    @property\n",
    "    def sensitivity(self):\n",
    "        return self.__sensitivity\n",
    "    \n",
    "    @property\n",
    "    def specificity(self):\n",
    "        return self.__specificity\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return self.__accuracy\n",
    "\n",
    "    @property\n",
    "    def recall_score(self):\n",
    "        return self.__recall_score\n",
    "    \n",
    "    @property\n",
    "    def precision_score(self):\n",
    "        return self.__precision_score\n",
    "    \n",
    "    @property\n",
    "    def missclassification_error(self):\n",
    "        return self.__missclassification_error\n",
    "    \n",
    "    def __summary_data(self):\n",
    "        self.__confusion_matrix = sklearn.metrics.confusion_matrix(self.__y_true, self.__y_pred)\n",
    "        tn, fp, fn, tp = self.__confusion_matrix.ravel()\n",
    "        self.__sensitivity: float = tp / (tp + fn)\n",
    "        self.__specificity: float = tn / (tn + fp)\n",
    "        self.__accuracy: float = (tn + tp) / (tn + fp + fn + tp)\n",
    "        self.__missclassification_error: float = 1 - self.__accuracy\n",
    "        self.__recall_score = sklearn.metrics.recall_score(self.__y_true, self.__y_pred)\n",
    "        self.__precision_score = sklearn.metrics.precision_score(self.__y_true, self.__y_pred)\n",
    "            \n",
    "    def __repr__(self):\n",
    "\n",
    "        r2 = lambda x: round(x * 100,2)\n",
    "        \n",
    "        return(\n",
    "                \"Confusion Matrix:\\n{}\".format(self.__confusion_matrix)\n",
    "               +\"\\n\"\n",
    "               +\"Accuracy: {}%\".format(r2(self.__accuracy))\n",
    "               +\"\\n\"\n",
    "               +\"Missclassification Error: {}%\".format(r2(self.__missclassification_error))\n",
    "               +\"\\n\"\n",
    "               +\"Sensitivity: {}%\".format(r2(self.__sensitivity))\n",
    "               +\"\\n\"\n",
    "               +\"Specificity: {}%\".format(r2(self.__specificity))\n",
    "               +\"\\n\"\n",
    "               +\"Recall Score: {}%\".format(r2(self.__recall_score))\n",
    "               +\"\\n\"\n",
    "               +\"Precision Score: {}%\".format(r2(self.__precision_score))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x7fac41010550>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"feedback-prize-effectiveness/train.csv\")\n",
    "test_data = pd.read_csv(\"feedback-prize-effectiveness/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36765, 5) (10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "1  5a88900e7dc1  D72CB1C11673   \n",
       "2  9790d835736b  D72CB1C11673   \n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \n",
       "0  Making choices in life can be very difficult. ...           Lead  \n",
       "1  Seeking multiple opinions can help a person ma...       Position  \n",
       "2                     it can decrease stress levels           Claim  \n",
       "3             a great chance to learn something new           Claim  \n",
       "4               can be very helpful and beneficial.           Claim  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36765 entries, 0 to 36764\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   discourse_id             36765 non-null  object\n",
      " 1   essay_id                 36765 non-null  object\n",
      " 2   discourse_text           36765 non-null  object\n",
      " 3   discourse_type           36765 non-null  object\n",
      " 4   discourse_effectiveness  36765 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lead', 'Position', 'Claim', 'Evidence', 'Counterclaim',\n",
       "       'Rebuttal', 'Concluding Statement'], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.discourse_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adequate', 'Ineffective', 'Effective'], dtype=object)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.discourse_effectiveness.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO: Build a cross table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Discourse Effectiveness\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adequate       20977\n",
       "Effective       9326\n",
       "Ineffective     6462\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Count of Discourse Effectiveness\")\n",
    "\n",
    "train_data.discourse_effectiveness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discourse Effectiveness Percent of Total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adequate       0.570570\n",
       "Effective      0.253665\n",
       "Ineffective    0.175765\n",
       "Name: discourse_effectiveness, dtype: float64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Discourse Effectiveness Percent of Total\")\n",
    "\n",
    "train_data.discourse_effectiveness.value_counts() / train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.replace({\"Ineffective\":0,\"Adequate\":1,\"Effective\":2},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20977\n",
       "2     9326\n",
       "0     6462\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.discourse_effectiveness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "   discourse_effectiveness  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:,:-1].values\n",
    "y_train = train_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Matrix: (36765, 4)\n",
      "Target:(36765,)\n",
      "Test Feature Matrix: (10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Features Matrix: {X_train.shape}\"\n",
    "+ \"\\n\"\n",
    "+ f\"Target:{y_train.shape}\" +\n",
    "\"\\n\"\n",
    "+ f\"Test Feature Matrix: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [*nlp.pipe(X_train[:,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[\"discourse_text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns number of characters\n",
    "len(docs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns number of words\n",
    "len(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADP adposition\n",
      "PRON pronoun\n",
      "NOUN noun\n",
      "PUNCT punctuation\n",
      "VERB verb\n",
      "SCONJ subordinating conjunction\n",
      "DET determiner\n",
      "AUX auxiliary\n",
      "ADJ adjective\n",
      "PART particle\n",
      "PROPN proper noun\n"
     ]
    }
   ],
   "source": [
    "for i in Counter(token.pos_ for token in docs[1]).keys():\n",
    "    print(i,spacy.explain(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_count(doc):\n",
    "    nn_count = 0   #Noun\n",
    "    pr_count = 0   #Pronoun\n",
    "    vb_count = 0   #Verb\n",
    "    adv_count = 0  #Adverb\n",
    "    con_count = 0  #Conjuntion\n",
    "    adj_count = 0  #Adjective\n",
    "    intj_count = 0   #Interjection\n",
    "    num_count = 0   #Numerics\n",
    "    \n",
    "    # sent = nltk.word_tokenize(sent)\n",
    "    # sent = nltk.pos_tag(sent)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN': #Noun\n",
    "            nn_count += 1\n",
    "\n",
    "        if token.pos_ == \"PRON\": #Pronoun\n",
    "            pr_count += 1\n",
    "        \n",
    "        if token.pos_ == \"CONJ\": #Conjunction\n",
    "            con_count += 1\n",
    "\n",
    "        if token.pos_ == 'VERB': #Verb\n",
    "            vb_count += 1\n",
    "\n",
    "        if token.pos_ == 'ADV': #Adverb\n",
    "            adv_count += 1\n",
    "        \n",
    "        if token.pos_ == 'ADJ': #Adjective\n",
    "            adj_count += 1\n",
    "\n",
    "        if token.pos_ == 'INTJ': #Interjection\n",
    "            intj_count += 1\n",
    "\n",
    "        if token.pos_ == 'NUM': #Numerics\n",
    "            num_count += 1\n",
    "    \n",
    "    return pd.Series([nn_count, pr_count, vb_count, adv_count, con_count, adj_count, intj_count, num_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(df, col):\n",
    "    df[f\"{col}_num_words\"] = df[col].apply(lambda x: len(str(x).split()))\n",
    "    df[f\"{col}_num_unique_words\"] = df[col].apply(lambda x: len(set(str(x).split())))\n",
    "    df[f\"{col}_num_chars\"] = df[col].apply(lambda x: len(str(x)))\n",
    "    df[f\"{col}_num_stopwords\"] = df[col].apply(lambda x: len([w for w in str(x).lower().split() if w in nlp.Defaults.stop_words]))\n",
    "    # df[f\"{col}_num_punctuations\"] = df[col].progress_apply(lambda x: len([c for c in str(x) if c in list(string.punctuation)]))\n",
    "    df[f\"{col}_num_words_upper\"] = df[col].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "    df[f\"{col}_num_words_title\"] = df[col].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "    df[f\"{col}_mean_word_len\"] = df[col].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "    # df[f\"{col}_num_paragraphs\"] = df[col].progress_apply(lambda x: len(x.split('\\n')))\n",
    "    # df[f\"{col}_num_contractions\"] = df[col].progress_apply(contraction_count)\n",
    "    # df[f\"{col}_polarity\"] = df[col].progress_apply(lambda x: TextBlob(x).sentiment[0])\n",
    "    # df[f\"{col}_subjectivity\"] = df[col].progress_apply(lambda x: TextBlob(x).sentiment[1])\n",
    "    df[[f'{col}_nn_count',f'{col}_pr_count',f'{col}_con_count',f'{col}_vb_count',f'{col}_adv_count',f'{col}_adj_count',f'{col}_intj_count',f'{col}_num_count']] = df[col].apply(pos_count)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"discourse_text_docs\"] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = text_features(train_data,\"discourse_text_docs\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data2.drop(columns={'discourse_effectiveness'}).copy()\n",
    "y = train_data2.discourse_effectiveness.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train2 = cv.fit_transform(X.discourse_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train2,y,test_size=0.25,random_state=8)\n",
    "\n",
    "mn_classifier = MultinomialNB(alpha=14)\n",
    "\n",
    "mn_classifier.fit(X_train,y_train)\n",
    "\n",
    "ypred = mn_classifier.predict(X_test)\n",
    "\n",
    "# sklearn.metrics.confusion_matrix(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6119451697127938"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train2 = cv.fit_transform(X.discourse_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train2,y,test_size=0.25,random_state=8)\n",
    "\n",
    "mn_classifier = MultinomialNB(alpha=14.4)\n",
    "\n",
    "mn_classifier.fit(X_train,y_train)\n",
    "\n",
    "ypred = mn_classifier.predict(X_test)\n",
    "\n",
    "# sklearn.metrics.confusion_matrix(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.608899042645779"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variables = pd.get_dummies(train_data2.discourse_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_text_docs_mean_word_len</th>\n",
       "      <th>discourse_text_docs_nn_count</th>\n",
       "      <th>discourse_text_docs_pr_count</th>\n",
       "      <th>discourse_text_docs_con_count</th>\n",
       "      <th>discourse_text_docs_vb_count</th>\n",
       "      <th>discourse_text_docs_adv_count</th>\n",
       "      <th>discourse_text_docs_adj_count</th>\n",
       "      <th>discourse_text_docs_intj_count</th>\n",
       "      <th>discourse_text_docs_num_count</th>\n",
       "      <th>Claim_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Lead_x</th>\n",
       "      <th>Position_x</th>\n",
       "      <th>Rebuttal_x</th>\n",
       "      <th>Claim_y</th>\n",
       "      <th>Concluding Statement_y</th>\n",
       "      <th>Counterclaim_y</th>\n",
       "      <th>Evidence_y</th>\n",
       "      <th>Lead_y</th>\n",
       "      <th>Position_y</th>\n",
       "      <th>Rebuttal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.731343</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.121951</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.027778</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.611111</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36761</th>\n",
       "      <td>5.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36762</th>\n",
       "      <td>4.260870</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36763</th>\n",
       "      <td>4.341463</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36764</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36765 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       discourse_text_docs_mean_word_len  discourse_text_docs_nn_count  \\\n",
       "0                               3.731343                            10   \n",
       "1                               4.121951                             6   \n",
       "2                               4.000000                             3   \n",
       "3                               4.027778                             9   \n",
       "4                               4.611111                             4   \n",
       "...                                  ...                           ...   \n",
       "36760                           5.000000                             4   \n",
       "36761                           5.333333                             4   \n",
       "36762                           4.260870                             4   \n",
       "36763                           4.341463                            12   \n",
       "36764                           5.000000                             2   \n",
       "\n",
       "       discourse_text_docs_pr_count  discourse_text_docs_con_count  \\\n",
       "0                                 6                              8   \n",
       "1                                 7                              5   \n",
       "2                                 4                              3   \n",
       "3                                14                              9   \n",
       "4                                 2                              4   \n",
       "...                             ...                            ...   \n",
       "36760                             3                              2   \n",
       "36761                             0                              1   \n",
       "36762                             5                              3   \n",
       "36763                            15                             20   \n",
       "36764                             1                              1   \n",
       "\n",
       "       discourse_text_docs_vb_count  discourse_text_docs_adv_count  \\\n",
       "0                                 1                              0   \n",
       "1                                 0                              0   \n",
       "2                                 1                              0   \n",
       "3                                 2                              0   \n",
       "4                                 0                              0   \n",
       "...                             ...                            ...   \n",
       "36760                             2                              0   \n",
       "36761                             1                              0   \n",
       "36762                             0                              0   \n",
       "36763                             1                              0   \n",
       "36764                             0                              0   \n",
       "\n",
       "       discourse_text_docs_adj_count  discourse_text_docs_intj_count  \\\n",
       "0                                  2                               1   \n",
       "1                                  4                               0   \n",
       "2                                  1                               0   \n",
       "3                                  5                               0   \n",
       "4                                  0                               0   \n",
       "...                              ...                             ...   \n",
       "36760                              2                               0   \n",
       "36761                              1                               0   \n",
       "36762                              3                               0   \n",
       "36763                              6                               0   \n",
       "36764                              1                               0   \n",
       "\n",
       "       discourse_text_docs_num_count  Claim_x  ...  Lead_x  Position_x  \\\n",
       "0                                  0        0  ...       1           0   \n",
       "1                                  0        0  ...       0           1   \n",
       "2                                  0        1  ...       0           0   \n",
       "3                                  1        0  ...       0           0   \n",
       "4                                  0        0  ...       0           0   \n",
       "...                              ...      ...  ...     ...         ...   \n",
       "36760                              1        1  ...       0           0   \n",
       "36761                              0        1  ...       0           0   \n",
       "36762                              0        0  ...       0           1   \n",
       "36763                              0        0  ...       0           0   \n",
       "36764                              0        0  ...       0           0   \n",
       "\n",
       "       Rebuttal_x  Claim_y  Concluding Statement_y  Counterclaim_y  \\\n",
       "0               0        0                       0               0   \n",
       "1               0        0                       0               0   \n",
       "2               0        1                       0               0   \n",
       "3               0        0                       0               0   \n",
       "4               0        0                       0               1   \n",
       "...           ...      ...                     ...             ...   \n",
       "36760           0        1                       0               0   \n",
       "36761           0        1                       0               0   \n",
       "36762           0        0                       0               0   \n",
       "36763           0        0                       0               0   \n",
       "36764           0        0                       1               0   \n",
       "\n",
       "       Evidence_y  Lead_y  Position_y  Rebuttal_y  \n",
       "0               0       1           0           0  \n",
       "1               0       0           1           0  \n",
       "2               0       0           0           0  \n",
       "3               1       0           0           0  \n",
       "4               0       0           0           0  \n",
       "...           ...     ...         ...         ...  \n",
       "36760           0       0           0           0  \n",
       "36761           0       0           0           0  \n",
       "36762           0       0           1           0  \n",
       "36763           1       0           0           0  \n",
       "36764           0       0           0           0  \n",
       "\n",
       "[36765 rows x 23 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2.merge(dummy_variables,left_on=train_data2.index, right_on= dummy_variables.index).iloc[:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_data = sparse.hstack(((X_train2,train_data2.iloc[:,6:].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_training_data,y,test_size=0.25,random_state=8)\n",
    "\n",
    "mn_classifier = MultinomialNB(alpha=14.4)\n",
    "\n",
    "mn_classifier.fit(X_train,y_train)\n",
    "\n",
    "ypred = mn_classifier.predict(X_test)\n",
    "\n",
    "# sklearn.metrics.confusion_matrix(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6071583986074848"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=300, criterion=\"entropy\", max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0, max_features=\"sqrt\", max_leaf_nodes=None, min_impurity_decrease=0, bootstrap=True, oob_score=False, n_jobs=None, random_state=8, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0, max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(ccp_alpha=0, criterion=&#x27;entropy&#x27;,\n",
       "                       min_impurity_decrease=0, min_weight_fraction_leaf=0,\n",
       "                       n_estimators=300, random_state=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(ccp_alpha=0, criterion=&#x27;entropy&#x27;,\n",
       "                       min_impurity_decrease=0, min_weight_fraction_leaf=0,\n",
       "                       n_estimators=300, random_state=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(ccp_alpha=0, criterion='entropy',\n",
       "                       min_impurity_decrease=0, min_weight_fraction_leaf=0,\n",
       "                       n_estimators=300, random_state=8)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455613577023499"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
